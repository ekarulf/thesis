%!TEX root = karulf-thesis.tex
\chapter{Background}
Steve Cousins, CEO of the robotics research institution \emph{Willow Garage}, suggests that ``in the next ten to twenty years our culture will experience a personal robotics revolution much like the personal computing revolution of the 1980's and 1990's''. \cite{Cousins} While we agree with Dr. Cousins, we believe that the advancement of robotics in our society is limited by the control interfaces. The emphasis of robot control software focuses on teleoperation, direct remote control, of a single robot by a single human. In this paper we explore the limitations of existing robot human-robot interfaces and we present a new paradigm for human-robot interaction.

We believe there is a growing need for robot control interfaces that allow a single user to control multiple robots simultaneously. In Section~\ref{existing_hri}, we describe several existing interfaces designed for one human to control one robot. We believe that these existing interfaces will not scale to support more complex, real-world tasks. We propose a paradigm for human-robot interaction known as blended autonomy. Blended autonomy grants the human operator a high-level abstraction for providing goals to a robot's artificial intelligence while retaining the flexibility to directly teleoperate a robot. This dynamic level of autonomy grants users the ability to control multiple robots concurrently. While the concept of blended autonomy is new to human-robot interaction, it is well established within other disciplines.

We argue that interfaces based on elements from computer video games are effective tools for the control of large robot teams. In Section~\ref{video_games} we introduce several genres of video games. We describe how to apply elements from various video game genres in robot control interfaces. We present RIDE, the Robot Interactive Display Environment, an example of such an interface. RIDE contains two different modes, a supervisory control mode and a direct control mode, to support blended autonomy. The supervisory mode borrows display and control mechanics from real-time strategy games to with to allow for goal-oriented control of many robots. The direct mode borrows visual elements from racing games for a more fine-grained control of a single robot. Additional details of RIDE's design, including the transition between the two modes, is described in Section~\ref{ui}.

To evaluate the effectiveness of the RIDE interface, and of the notification system in particular, we conducted a formal user study. Our two-condition experiment asked subjects to perform a search task using two simulated robots in a small house. We instrumented the application to record the user's behavior and timing information. This results of this data, combined with the pre-experiment and post-experiment questionnaires, is presented in Section~\ref{results}.

Human-Robot Interaction, also known as HRI, is a discipline studying the interactions of humans and robots. This multidisciplinary field deals with draws on principles of artificial intelligence, social psychology, and Human-Computer Interaction. Human-Computer Interaction, know as HCI, is a well established field within the realm of Computer Science. The Association for Computing Machinery Special Interest Group on Human-Computer Interaction (SIGCHI) defines HCI as ``the study and practice of the design, implementation, use, and evaluation of interactive computing systems.'' \cite{SIGCHI} Due to the young age of HRI as a discipline, most of principles of HRI are adapted from the much broader field of HCI. Owing to these adaptations from HCI, existing HRI interfaces are limited to keyboard and mouse interfaces. While advances in hardware allow HCI scientists a much richer selection of interfaces, these interfaces have not become common place within the HRI community. A small selection of modern HRI interfaces are illustrated in Figure~\ref{existing-robot-ui}.

\begin{figure}[ht]
\begin{center}
\includegraphics[width=3.5in]{images/placeholder.png}
\caption{Existing 2D and 3D HRI interfaces\label{fig:existing-robot-ui}}
\end{center}
\end{figure}

Similarly, video games represent another young, multi-disciplinary field within the Computer Science community. Video games, like HRI, draw many of their principles from the world of HCI. Originally created as an application of computer graphics for use in the entertainment industry, video game development has matured into an independent industry in its own right. The popularity of video games has grown significantly throughout the past decade. The Entertainment Software Association estimates 68\% of American households now play computer or video games. \cite{ESA} This large demographic represents a pool of users already versed in exploring 3D virtual worlds interactively. In these interactions users are not only perceiving the a virtual world through simulated senses, but users are also performing actions and controlling their presence in this world through input devices, eg., a mouse and keyboard.

% TODO: Insert transition before "For example,"
Video games represent not only a large entertainment medium but they also have utility and direct applications to the fields of artificial intelligence and machine learning. Dr. Luis Von Ahn found that video games can be an effective tool for generating training data sets for machine learning. \cite{GWAP} Dr. Von Ahn developed special video games he calls ``games with a purpose''.  These games provide a way to solve problems that may be considered trivial for humans, yet are very challenging for computers. In these games the interaction of the human and the computer has changed to include the human in the computation of data.

Dr. Daniel Grollman, in his dissertation work, applied a video games interface with HRI principles to capture training data for robotic user interfaces. \cite{Grollman} Grollman's application, RGame, recorded userâ€™s actions as they controlled a robotic dog and taught it to play soccer. Dr. Grollman was able to create an AI model for shooting and defending using the aggregate of data collected from RGame. Similar to Dr. Von Ahn's research, the RGame interface allowed the computer request information from the user to help it solve a problem.

As the field of robotics continues to evolve and mature, I predict the need for training data and effective user interface design will become more pronounced and prevalent. I propose that the robotics community should apply video game design concepts to robot control and display interfaces. I hypothesize that resulting interfaces will be intuitive and easy to use for users regardless of video game experience.
