%!TEX root = karulf-thesis.tex
\chapter{Conclusion}

We propose applying techniques and design elements from video games to address weaknesses in existing human-robot interfaces. We submitted RIDE, an interface for controlling heterogeneous robot teams using design elements from video games. We introduced the concept of ``sliding autonomy'' to allow the human operator and the robot to vary the degree of robot autonomy dependent on the situation. We presented an overview of the implemented system, RIDE, and using the ROS middleware framework. Finally we present the results of some preliminary user studies.

\section{Future Work}
\label{section:futurework}
Observing the user interface usage, during the user studies, revealed several weak points in our implementation. We believe that small enhancements to RIDE will greatly benefit the end user experience.

In Section~\ref{sub:info_exchange} we introduced Nielsen's prior work designing ecological interfaces for robotics. While the paper was a large influence on our design work, we feel our interface would benefit from additional visual cues. In their proposed UI, Nielsen extruded the known elements from the coverage map vertically to create an approximate three dimensional representation \cite{Nielsen_Teleoperation}. In our original design, we rejected this design element as we believed it misrepresented the third dimension to the user. However, during user studies, the users often mentioned it was difficult to position the camera for teleoperation while keeping the map visible.

During our user studies we also discovered that many users, especially users without prior robotics experience, found the robots to behave in a counterintuitive manner. As an example, the path planning algorithm we used in our study is weighted in a way that often chooses a longer, more circuitous route to avoid obstacles, than a more direct route that passes near obstacles. We believe that exposing more behavioral information will reduce the cognitive load on users. Future versions of the RIDE application would benefit from adapting the prior work in visualizing autonomous navigation systems to the field of robotics.

\section{Future User Studies}
\label{sec:futurestudy}
While successful, the design of the preliminary user study introduced several mitigating factors that prevented a definitive acceptance of our hypothesis. We feel our hypothesis can be clearly demonstrated with a revised experimental design. We identify and propose solutions to address several major problems with our experimental design.

In our preliminary user study, our intent was to provide a common set of knowledge in terms of robotics and video game experience. Unfortunately, by providing this training we made the analysis between experience groups much more difficult. As a result, we have widened our target audience to include users without robotics experience. In future studies, we plan to limit our training to include only speak-aloud practice to avoid introducing any potential biases.

In addition to the problems in our pre-experiment preparation, we have identified several ways to improve upon the experimental design itself. The purpose of our experiments was to prove applying video game principles to HRI interfaces will improve usability. In order to prove our hypothesis, we used notification display as an independent variable and recorded completion time as a measure of usability. While this is a valid approach, we would like to re-focus our experiment to directly test our mixed-mode interface by measuring cognitive load. 

In order to evaluate the sliding autonomy approach, we will run a randomized three-condition within subject experiment. Instead of using notifications we will use the control modes as our independent variable. This gives us three conditions to test: direct only control, supervisory only control, and blended control. This would allow us to directly compare the given modes and record metrics on the blended control interfaces, such as time spent in each mode and the number of mode switches.

As mentioned above, while we can correlate successful task completion with improved usability, we would like to utilize a more direct metric. Researchers at the United States National Aeronautics and Space Administration (NASA) developed a metric for describing a human's workload while accomplishing a task. The metric, known as the ``Task Load Index,'' is computed from a user's perceived workload on six sub-scales: mental demand, physical demand, temporal demand, performance, effort, and frustration \cite{NASA_TLX}. Our revised user study would ask subjects to rate their workload on each of the Task Load Index's six sub-scales after each experiment. At the conclusion of the user study, we would ask users to answer the fifteen questions to determine the weighting of the sub-scales when computing the task load index \cite{NASA_TLX20}.

Given the context of testing the control modes using the NASA Task Load Index, we decided to modify the subjects' tasks to more accurately represent our use cases. These new - more challenging - tasks would require a larger simulated world, more robots, and a different scenario. A weakness in the preliminary user study's scenario, is that the robots were able to complete their task immediately. This model does not match a use case in the real world, where most actions will require a non-zero amount of time to complete. Such a study, we believe, will show the benefits of mixed-mode interfaces across the whole population when even experienced users cannot realistically monitor all robots at once.

