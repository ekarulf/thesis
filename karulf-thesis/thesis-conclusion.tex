\chapter{Conclusion}

We propose applying techniques and design elements from video games to address weaknesses in existing human-robot interfaces. We submitted RIDE, an interface for controlling heterogenous robot teams using design elements from video games. We introduced the concept of ``sliding autonomy'' to allow the human operator and the robot to vary the degree of robot autonomy dependent on the situation. We presented an overview of the implemented system, RIDE, using the ROS middleware framework. Finally we present the results of some preliminary user studies. Though the results of the user studies were mixed, we remain confident that refinements to the interface design and the user study process will provide clear results in future work.

\section{Future Work}
\label{section:futurework}
Observing the user interface use during the user studies revealed several weak points in our implementation. We believe that small enhancements to RIDE will greatly benefit the end user experience. % The modifications are broken into two categories: user interface changes and middleware changes.
We identified three major changes to our user interface: enhancing the ecological interfaces and creating actionable notifications.

In Section~\ref{sub:info_exchange} we introduced Nielsen's prior work designing ecological interfaces for robotics. While the paper was a large influence on our design work, we feel our interface would benefit from additional visual cues. In their proposed UI, Nielsen extruded the known elements from the coverage map vertically to create an approximate three dimensional representation. \ref{Nielsen_Teleoperation} In our original design, we rejected this design element as we believed it misrepresented the third dimension to the user. However during user studies, users often mentioned it was difficult to position the camera for teleoperation while keeping the map visible.

During our user studies we also found that many users, especially users without prior robotics experience, found the robots to behave in a counter intuitive manner. As an example, the path planning algorithm we used in our study is weighted in a way that often chooses a longer, more circuitous route to avoid obstacles than a more direct route that passes near obstacles. We believe that exposing more behavioral information will reduce the cognitive load on users. Future versions of the RIDE application would benefit from adapting the prior work in visualizing autonomous navigation systems to the field of robotics.

% TODO: Sensor coverage map?

% TODO: Notifications

\section{Future User Studies}
\label{sec:futurestudy}
As noted in Section~\ref{sec:study-results}, the design of the preliminary user study introduced several mitigating factors that prevented a clear acceptance of our hypothesis. Though the study returned some results, we feel our hypothesis can be clearly demonstrated with a revised experimental design. We have identified the several major problems with our experimental design. We propose several modifications to address the problems with our preliminary research.

In our preliminary user study, our intent was to provide a common set of knowledge in terms of robotics and video game experience. Unfortunately, by providing this training we made the analysis between experience groups much more difficult. As a result, we have widened our target audience to include users without robotics experience. In future studies, we plan to limit our training to only include speak-aloud practice to avoid introducing any potential biases.

In addition to the problems in our pre-experiment preparation, we have identified several ways to improve upon the experimental design itself. The purpose of our experiments was to prove applying video game principles to HRI interfaces will improve usability. In order to prove our hypothesis, we used notification display as an independent variable and recorded completion time as a measure of usability. While this is a valid approach, we would like to refocus our experiment to directly test our ``blended autonomy'' interface by measuring cognitive load. 

In order to evaluate the blended autonomy approach, we will run a randomized three-condition within subject experiment. Instead of using notifications we will use the control modes as our independent variable. This gives us three conditions to test: only direct control, only supervisory control, and blended control. This would allow us to directly compare the given modes and record metrics on the blended control interfaces such as time spent in each mode and the number of mode switches.

As mentioned above while we can correlate successful task completion with improved usability, we would like to utilize a more direct metric. Researchers at the United States National Aeronautics and Space Administration (NASA) developed a metric for describing a human's workload while accomplishing a task. The metric, known as the ``Task Load Index'', is computed from a user's perceived workload on six sub-scales: mental demand, physical demand, temporal demand, performance, effort, and frustration. \cite{NASA_TLX} Our revised user study would ask participants to rate their workload on each of the Task Load Index's six sub-scales after each experiment. At the conclusion of the user study, we would ask users to answer the fifteen questions to determine the weighting of the sub-scales when computing the task load index. \cite{NASA_TLX20}

Given the context of testing the control modes using the NASA Task Load Index, we decided to modify the tasks to more accurately represent our use cases. The preliminary user study asked participants to find several boxes hidden randomly throughout a small house using two robots. We would like to add specificity to the roles participants will be pretending. We tell participants that several hikers are lost in the woods, the participant works for the Sheriff's office and they are controlling robots to assist in the search. A weakness in the preliminary study is that the robots were able to complete their task immediately, while most actions taken by a robot will require a non-zero amount of time to complete. In our scenario, we will ask participants to remain with the hiker and broadcast a notification beacon until a rescue crew arrives. We believe that by assigning a more difficult task, the differences between the user interfaces will become more pronounced.